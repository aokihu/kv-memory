## Context

当前记忆系统基于SQLite实现Key-Value存储，提供HTTP API和MCP工具进行记忆操作。系统支持单个记忆的读写，记忆之间通过links字段建立关联关系。每个记忆包含metadata（包括memory_score）和links数组（包含link_weight）。

用户需要批量读取关联记忆来理解完整上下文，但当前系统需要手动多次调用API。本项目旨在实现批量读取功能，支持深度优先遍历、权重排序、去重和总量控制。

## Goals / Non-Goals

**Goals:**
1. 实现HTTP API批量读取端点，支持深度优先遍历关联记忆
2. 扩展MCP Memory工具，支持批量读取参数
3. 实现权重排序算法：按`link_weight × memory_score`降序排序
4. 实现去重机制：基于memory key防止重复读取
5. 实现限制控制：深度≤6，广度≤20，总量≤50
6. 保持向后兼容性：现有单记忆读取接口不变

**Non-Goals:**
1. 修改记忆数据模型结构
2. 实现记忆的批量写入功能
3. 修改记忆关联的管理逻辑
4. 实现记忆的自动合并或删除
5. 修改memory_score的计算方式

## Decisions

### 1. 深度优先遍历算法
**选择深度优先遍历（DFS）而非广度优先遍历（BFS）**
- **理由**：深度优先更符合记忆关联的语义，优先探索深度关联能更快获取相关上下文
- **替代方案**：广度优先遍历会先获取所有直接关联，但可能错过深度相关的重要记忆
- **实现**：递归或栈实现的DFS，记录已访问记忆key用于去重

### 2. 权重排序策略
**选择`link_weight × memory_score`作为排序依据**
- **理由**：综合考虑关联强度（link_weight）和记忆重要性（memory_score）
- **替代方案**：仅按link_weight或仅按memory_score排序，但两者结合更全面
- **实现**：从记忆metadata获取memory_score，从links获取link_weight，计算乘积后排序

### 3. 限制控制策略
**选择三层限制：深度、广度、总量**
- **理由**：防止无限递归和过大响应，保护系统性能
- **深度限制**：防止过深遍历（最大6层）
- **广度限制**：防止每层获取过多记忆（最大20个）
- **总量限制**：防止总响应过大（最大50条）
- **实现**：遍历时实时检查，达到任一限制立即停止

### 4. 去重机制
**选择基于memory key的简单去重**
- **理由**：memory key唯一标识记忆，简单有效
- **替代方案**：基于内容哈希去重，但复杂度高且可能误判
- **实现**：使用Set记录已访问key，遍历时跳过已访问记忆

### 5. API设计
**选择新增端点而非修改现有端点**
- **理由**：保持向后兼容性，现有客户端不受影响
- **新端点**：`GET /api/memories/{key}/bulk`
- **参数**：`depth`、`breadth`、`total`（可选，有默认值和最大值）
- **响应**：包含目标记忆、关联记忆数组、遍历元数据

### 6. MCP工具扩展
**选择扩展现有Memory工具参数**
- **理由**：保持工具一致性，用户学习成本低
- **新增参数**：`depth`、`breadth`、`totalLimit`
- **响应格式**：兼容现有MCP工具输出，增加批量读取结果

## Risks / Trade-offs

### [风险] 性能问题：深度遍历可能产生大量数据库查询
- **缓解措施**：
  1. 实现限制控制（深度、广度、总量）
  2. 考虑批量查询优化，减少数据库往返次数
  3. 实现查询缓存，避免重复查询相同记忆

### [风险] 内存使用：大量记忆数据可能占用过多内存
- **缓解措施**：
  1. 严格的总量限制（最大50条）
  2. 流式处理，边遍历边返回，不一次性加载所有数据
  3. 实现内存使用监控

### [风险] 循环引用：记忆关联可能形成循环
- **缓解措施**：
  1. 深度限制防止无限递归
  2. 去重机制防止重复处理同一记忆
  3. 实现循环检测，发现循环时记录日志

### [风险] 排序算法复杂度
- **缓解措施**：
  1. 每层只对有限数量记忆排序（广度限制）
  2. 使用高效排序算法
  3. 考虑预计算或缓存排序结果

### [权衡] 功能完整性 vs 性能
- **选择**：优先保证性能，通过严格限制控制响应大小和查询次数
- **理由**：批量读取是辅助功能，不应影响系统核心性能

### [权衡] 灵活性 vs 安全性
- **选择**：提供参数自定义，但设置合理上限
- **理由**：满足不同使用场景，同时防止滥用

## Migration Plan

### 阶段1：实现核心逻辑
1. 实现深度优先遍历算法
2. 实现权重排序逻辑
3. 实现去重和限制控制
4. 单元测试验证算法正确性

### 阶段2：HTTP API实现
1. 新增批量读取端点
2. 实现参数验证和错误处理
3. 集成核心逻辑到API层
4. API测试验证功能

### 阶段3：MCP工具扩展
1. 扩展Memory工具参数
2. 实现MCP协议适配
3. 集成核心逻辑到MCP层
4. MCP工具测试

### 阶段4：部署和验证
1. 部署到测试环境
2. 性能测试和负载测试
3. 用户验收测试
4. 生产环境部署

### 回滚策略
- 新端点为新增功能，不影响现有功能
- 出现问题可禁用新端点，回退到单记忆读取
- MCP工具扩展可版本回退

## Open Questions

1. **memory_score获取**：memory_score在metadata中的具体字段名是什么？
2. **性能优化**：是否需要实现记忆查询的批量优化？
3. **缓存策略**：是否需要对频繁访问的记忆实现缓存？
4. **监控指标**：需要监控哪些指标来评估批量读取功能的使用和性能？